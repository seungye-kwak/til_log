다항회귀
========

### 다항회귀
* 회귀가 독립변수의 단항식이 아닌 2차, 3차 방정식과 같은 다항식으로 표현되는 것 (선형회귀)
* 다항식의 차수(degree)가 높아질수록 매우 복잡한 피처 간의 관계까지 모델링이 가능함. 하지만 그럴수록 학습데이터에만 너무 맞춘 과적합이 발생하게 됨

### 편향-분산 트레이드오프(Bias-Variance Trade off)
![image](https://github.com/seungye-kwak/til_log/assets/112370282/021fba95-a5a0-4176-b65f-5f2a160d688b)  
* 고편향 : 매우 단순화된 모델로서 지나치게 한 방향성으로 치우친 경향
* 고분산(High Variance) : 학습데이터 하나 하나의 특성을 반영하면서 매우 복잡한 모델이 되었고 지나치게 변동성을 가지게 된 경우
* 우리가 지향해야 할 곳은 저편향/저분산(Low Bias/Low Variance). 하지만 쉽지 않음
* 상단 오른쪽의 저편향/고분산은 예측 결과가 실제 결과에 비교적 근접하지만, 예측 결과가 실제 결과를 중심으로 꽤 넓은 부분에 분포되어 있음
* 왼쪽의 고편향/저분산은 정확한 결과에서 벗어나면서도 예측이 특정 부분에 집중되어 있음
* 편향-분산 트레이드오프 : 일반적으로 편향과 분산은 한쪽이 높으면 한쪽이 낮아지는 경향이 있음. 편향이 높으면 분산은 낮아지고(과소적합), 반대로 분산이 높으면 편향이 낮아짐(과적합)
* 편향을 낮추고 분산을 높이면서 전체 오류가 가장 낮아지는 '골디락스' 지점을 통과하면서 분산을 지속적으로 높이면 전체 오류 값이 오히려 증가하면서 예측 성능이 다시 저하됨
* 편향과 분산이 서로 트레이드 오프를 이루면서 오류 Cost 값이 최대로 낮아지는 모델을 구축하는 것이 가장 효율적인 머신러닝 예측 모델을 만드는 방법  
![image](https://github.com/seungye-kwak/til_log/assets/112370282/78d5b68f-67eb-43dc-9158-13729bf7f097)
