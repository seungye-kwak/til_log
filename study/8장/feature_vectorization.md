피처 벡터화
===
## 1. 피처 벡터화
- 머신러닝 알고리즘에 맞게 텍스트 데이터를 숫자형 피처로 만들어주기 위해, 텍스트를 특정 의미 있는 숫자형 벡터값으로 변환하는 것
- 예시로 각 문서의 텍스트를 단어로 추출해 피처로 할당하고, 각 단어의 발생 빈도와 같은 값이 피처에 값으로 부여해 각 문서를 이 단어 피처의 발생 빈도 값으로 구성된 벡터로 만드는 방법이 있음
- 피처 벡터화는 기존 텍스트 데이터를 또 다른 형태의 피처의 조합으로 변경하기 때문에 넓은 범위의 피처 추출에 포함함

## 2. BOW (Bag of Words)
- 문서가 가지는 모든 단어(words)를 문맥이나 순서를 무시하고 일괄적으로 단어에 대해 빈도 값을 부여해 피처 값을 추출하는 모델
- 문서 내 모든 단어를 한꺼번에 봉투(Bag)안에 넣은 뒤 흔들어서 섞는다는 의미를 가짐
- 장점 : 쉽고 빠른 구축. 단순히 단어의 발생 횟수에 기반하지만 예상보다 문서의 특징을 잘 나타내어 전통적으로 여러 분야에서 활용도가 높음
- 단점 : 문맥 의미(Semantic Context) 반영 부족, 희소 행렬 문제
- BOW 모델에서 피처 벡터화를 수행한다는 것은 __모든 문서에서 모든 단어를 칼럼 형태로 나열하고 각 문서에서 해당 단어의 횟수나 정규화된 빈도를 값으로 부여하는 데이터 세트 모델로 변경하는 것__
- 일반적으로 BOW의 피처 벡터화는 두 가지 방식이 있음

  ### 2.1 카운트 기반의 벡터화
  - 단어 피처에 값을 부여할 때 각 문서에서 해당 단어가 나타나는 횟수, 즉 Count를 부여하는 경우를 카운트 벡터화라고 함
  - 카운트 벡터화에서는 카운트 값이 높을수록 중요한 단어로 인식됨
  - 하지만 카운트만 부여할 경우 그 문서의 특징을 나타내기보다는 언어의 특성상 문장에서 자주 사용될 수밖에 없는 단어까지 높은 값을 부여하게 됨
    
  ### 2.2 TF-IDF (Term Frequency - Inverse Document Frequency) 기반의 벡터화
  - 카운트 기반의 벡터화에서 나타는 단점을 보완하기 위해, __개별 문서에서 자주 나타나는 단어에 높은 가중치를 주되, 모든 문서에서 전반적으로 자주 나타나는 단어에 대해서는 패널티를 주는 방식__
  - scikit-learn의 CountVectorizer 클래스는 카운트 기반의 벡터화를 구현한 클래스. 단지 피처 벡터화만 수행하지는 않으며 소문자 일괄 변환, 토큰화, 스톱워드 필터링 등 전처리도 함께 수행함
  - 보통 CounterVectorizer에서는 사전 데이터 가공 > 토큰화 > 텍스트 정규화 > 피처 벡터화 과정으로 진행됨
  - scikit-learn에서 TF-IDF는 IFidfVectorizer 클래스를 이용함
    
  
